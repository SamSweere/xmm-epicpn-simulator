{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Level 5 is a good balance\n",
    "def compress_gzip(in_file_path, out_file_path, compresslevel=5):\n",
    "    with open(in_file_path, 'rb') as f_in:\n",
    "        with gzip.open(out_file_path, 'wb', compresslevel=compresslevel) as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "def compress_targz(in_file_path, out_file_path):\n",
    "    with tarfile.open(out_file_path, \"w:gz\") as tar:\n",
    "        tar.add(in_file_path, arcname=os.path.basename(in_file_path))\n",
    "\n",
    "def decompress_gzip(in_file_path, out_file_path):\n",
    "    with gzip.open(in_file_path, 'rb') as f_in:\n",
    "        with open(out_file_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "def decompress_targz(in_file_path, out_file_path):\n",
    "    decompressed_file_paths = []\n",
    "    with tarfile.open(in_file_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=out_file_path)\n",
    "        for i in range(len(tar.members)):\n",
    "            name = tar.members[i].name\n",
    "            decompressed_file_paths.append(os.path.join(out_file_path, name))\n",
    "    \n",
    "    return decompressed_file_paths\n",
    "\n",
    "def get_multiprocessing_pool(num_processes=None, gb_per_process=None):\n",
    "    # num_processes : the number of processes, if None the calculation is done based on the gb_per_process limit\n",
    "    # gb_per_process : the expected amount of ram one process needs, if None there is no limit\n",
    "\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    print(\"Number of cpu : \", cpu_count)\n",
    "    mem = virtual_memory().total * 1e-9  # System memory in gb\n",
    "    print(\"System memory: \", mem)\n",
    "\n",
    "    if num_processes:\n",
    "        print('Num processes defined by user')\n",
    "        num_processes = num_processes\n",
    "    else:\n",
    "        if gb_per_process:\n",
    "            max_precesses_mem = max(int(mem / float(gb_per_process)), 1)\n",
    "            if max_precesses_mem < cpu_count:\n",
    "                print('Num processes limited by memory')\n",
    "                num_processes = max_precesses_mem\n",
    "            else:\n",
    "                print('Num processes limited by cpu count')\n",
    "                num_processes = cpu_count\n",
    "        else:\n",
    "            print('Num processes limited by cpu count')\n",
    "            num_processes = cpu_count\n",
    "\n",
    "    print(\"Num processes:\", num_processes)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    return pool\n",
    "\n",
    "def run_apply_async_multiprocessing(func, argument_list, num_processes=None, gb_per_process=None):\n",
    "    # From: https://leimao.github.io/blog/Python-tqdm-Multiprocessing/\n",
    "\n",
    "    pool = get_multiprocessing_pool(num_processes=num_processes, gb_per_process=gb_per_process)\n",
    "\n",
    "    jobs = [pool.apply_async(func=func, args=(*argument,)) if isinstance(argument, tuple)\n",
    "            else pool.apply_async(func=func, args=(argument,)) for argument in argument_list]\n",
    "\n",
    "    pool.close()\n",
    "    result_list_tqdm = []\n",
    "    for job in tqdm(jobs):\n",
    "        result_list_tqdm.append(job.get())\n",
    "\n",
    "    return result_list_tqdm\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def targz_to_gzip(filepath, run_dir):    \n",
    "    # print(filepath)\n",
    "    decompressed_file_paths = decompress_targz(in_file_path=filepath, out_file_path=run_dir)\n",
    "    decompressed_file_path = decompressed_file_paths[0]\n",
    "    \n",
    "    gz_file_path = os.path.join(os.path.dirname(filepath), os.path.basename(decompressed_file_path) + '.gz')\n",
    "    # print(gz_file_path)\n",
    "    compress_gzip(decompressed_file_path, gz_file_path, compresslevel=5)\n",
    "\n",
    "    for decompressed_file_path in decompressed_file_paths:\n",
    "        os.remove(decompressed_file_path)\n",
    "\n",
    "    # Remove the original file\n",
    "    os.remove(filepath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_dir = '/home/sam/Documents/ESA/data/sim/simput'\n",
    "\n",
    "# data_dir = '/home/sam/Documents/ESA/data/sim/test_dataset'\n",
    "\n",
    "tar_gz_files = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.tar.gz'):\n",
    "            tar_gz_files.append(os.path.join(dirpath, filename))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "run_dir = '/home/sam/Documents/ESA/data/sim/tmp_gzip'\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from psutil import virtual_memory\n",
    "\n",
    "argument_list = []\n",
    "for filepath in tar_gz_files:\n",
    "    argument_list.append((filepath, run_dir))\n",
    "\n",
    "run_apply_async_multiprocessing(func=targz_to_gzip, argument_list=argument_list, num_processes=0, gb_per_process=0.1)\n",
    "\n",
    "print(\"Done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of cpu :  12\n",
      "System memory:  16.520716288000003\n",
      "Num processes limited by cpu count\n",
      "Num processes: 12\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# remove rundir\n",
    "shutil.rmtree(run_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}